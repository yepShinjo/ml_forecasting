{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b87615a-5d0a-4781-8666-291a6ff6b666",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting pystan==2.19.1.1\n",
      "  Using cached pystan-2.19.1.1.tar.gz (16.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting Cython!=0.25.1,>=0.22 (from pystan==2.19.1.1)\n",
      "  Using cached cython-3.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.12/site-packages (from pystan==2.19.1.1) (1.26.4)\n",
      "Using cached cython-3.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Building wheels for collected packages: pystan\n",
      "  Building wheel for pystan (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[3 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-install-drrf_rbz/pystan_a7a443591ee64c3890c5c9189372d14b/setup.py:61: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  \u001b[31m   \u001b[0m   self.version = node.value.s\n",
      "  \u001b[31m   \u001b[0m Cython>=0.22 and NumPy are required.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pystan\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pystan\n",
      "Failed to build pystan\n",
      "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (pystan)\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: prophet in /opt/conda/lib/python3.12/site-packages (1.1.6)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in /opt/conda/lib/python3.12/site-packages (from prophet) (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.12/site-packages (from prophet) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from prophet) (3.10.1)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /opt/conda/lib/python3.12/site-packages (from prophet) (2.2.3)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in /opt/conda/lib/python3.12/site-packages (from prophet) (0.73)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/conda/lib/python3.12/site-packages (from prophet) (4.67.1)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.12/site-packages (from prophet) (6.5.2)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.12/site-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=2.0.0->prophet) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=2.0.0->prophet) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=2.0.0->prophet) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=2.0.0->prophet) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=2.0.0->prophet) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib>=2.0.0->prophet) (3.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.0.4->prophet) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.0.4->prophet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.17.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.12/site-packages (1.37.1)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.1 in /opt/conda/lib/python3.12/site-packages (from boto3) (1.37.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.12/site-packages (from boto3) (0.11.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore<1.38.0,>=1.37.1->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.12/site-packages (from botocore<1.38.0,>=1.37.1->boto3) (2.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.1->boto3) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pystan==2.19.1.1\n",
    "!pip install prophet\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47333118-b97f-4f59-9671-d8ba256b4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import boto3\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4520c806-c787-4ef5-94d3-d408fba0c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'thedogspaw-small-forecast-data'  # <--- change to your S3 bucket\n",
    "\n",
    "# Connect to S3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def s3_get(key, local):\n",
    "    s3.download_file(bucket, key, local)\n",
    "    \n",
    "s3_get('datasets/thedogspaw_phppos_sales.csv',         '/tmp/sales.csv')\n",
    "s3_get('datasets/thedogspaw_phppos_sales_items.csv',   '/tmp/sales_items.csv')\n",
    "s3_get('datasets/thedogspaw_phppos_variations_combined.csv', '/tmp/variations_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93d047b-7171-4b20-8f4b-e55909524c19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_id</th>\n",
       "      <th>item_variation_id</th>\n",
       "      <th>quantity_purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sale_id  item_variation_id  quantity_purchased\n",
       "0        1                NaN                 1.0\n",
       "1        2                NaN                 1.0\n",
       "2        3                NaN                 1.0\n",
       "3        4                NaN                 1.0\n",
       "4        5                NaN                 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sales_df = pd.read_csv(\n",
    "    '/tmp/sales.csv',\n",
    "    usecols=['sale_id', 'sale_time',  'location_id'],\n",
    "    parse_dates=['sale_time'],\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "sales_items_df = pd.read_csv(\n",
    "    '/tmp/sales_items.csv',\n",
    "    usecols=['sale_id', 'item_variation_id', 'quantity_purchased'],\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "variations_combined_df = pd.read_csv('/tmp/variations_combined.csv')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)   # set to None to show all rows if needed\n",
    "\n",
    "display(sales_items_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6946e250-ecf8-4e8c-a213-dde6ebb5ee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sale_time', 'sale_id', 'location_id'], dtype='object')\n",
      "Index(['sale_id', 'item_variation_id', 'quantity_purchased'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sales_df.columns)\n",
    "print(sales_items_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e578a54-469b-4a72-b282-a422c4accabd",
   "metadata": {},
   "source": [
    "## No preprocessing columns needed for sales.csv and sales_items.csv NaN columns to Str\n",
    "## Since we dont even load them to the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ebe54b-05e9-40d4-aa82-6ef8704ed288",
   "metadata": {},
   "source": [
    "# Variations_combined is good, but we also need the data from sales_items_df and sales_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe68de-98b7-4fc2-9758-2951b19649e4",
   "metadata": {},
   "source": [
    "## We take quantity_purchased from sales_items_df We take sale_time from sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b930af-3cba-4349-89b0-83e218b76971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only join sale_time (not location_id)\n",
    "sales_items_with_time = sales_items_df.merge(\n",
    "    sales_df[['sale_id', 'sale_time']],\n",
    "    on='sale_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "930cbd74-1072-442e-a9d9-f53071e7f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add location and names from variations_combined_df\n",
    "combined_df= sales_items_with_time.merge(\n",
    "    variations_combined_df[['item_variation_id', 'location_id', 'variation_name', 'name']].drop_duplicates(),\n",
    "    on='item_variation_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca18eb38-fe12-4e8e-a2bc-1ab9f31bf304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a daily date column\n",
    "combined_df['sale_date'] = pd.to_datetime(combined_df['sale_time']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8935acc7-6f42-41e4-b3b7-f935991f69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate quantity sold per day, per variation, per location, with readable names\n",
    "agg_df = combined_df.groupby(\n",
    "    ['sale_date', 'item_variation_id', 'location_id', 'variation_name', 'name']\n",
    ")['quantity_purchased'].sum().reset_index()\n",
    "\n",
    "recent_daily_var_sales = agg_df.rename(\n",
    "    columns={\n",
    "        'sale_date': 'date',\n",
    "        'item_variation_id': 'variation_id',\n",
    "        'quantity_purchased': 'y'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6482b65-c5a6-4c8f-a92c-9c8cc0c4d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History check\n",
    "var_day_counts = (\n",
    "    recent_daily_var_sales.groupby(['location_id', 'variation_id'])['date']\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={'date': 'num_days_with_sales'})\n",
    ")\n",
    "var_day_counts['enough_history'] = var_day_counts['num_days_with_sales'] >= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b135abe0-0343-4f07-87e0-899f3ff9ee89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68c76abea9441b6bca648394bae5793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:35:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:35:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:35:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:35:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:35:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:35:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:35:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:35:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:35:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:35:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:35:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:35:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:35:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:35:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:35:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:35:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:35:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:35:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:35:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:35:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:35:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:35:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:36:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:36:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:36:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:36:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "lead_time_days = 7\n",
    "z = 1.65\n",
    "results = []\n",
    "\n",
    "for _, row in tqdm(var_day_counts.iterrows(), total=len(var_day_counts)):\n",
    "    loc = row['location_id']\n",
    "    var = row['variation_id']\n",
    "    enough = row['enough_history']\n",
    "    var_sales_history = recent_daily_var_sales[\n",
    "        (recent_daily_var_sales['location_id'] == loc) &\n",
    "        (recent_daily_var_sales['variation_id'] == var)\n",
    "    ].copy()\n",
    "    var_sales_history = var_sales_history.rename(columns={'date': 'ds', 'y': 'y'})\n",
    "    var_sales_history['ds'] = pd.to_datetime(var_sales_history['ds'])\n",
    "\n",
    "    cutoff_in_loop = var_sales_history['ds'].max() - pd.DateOffset(months=12)\n",
    "    var_sales_history = var_sales_history[var_sales_history['ds'] >= cutoff_in_loop]\n",
    "\n",
    "    reorder_level = None\n",
    "    replenish_level = None\n",
    "\n",
    "    if enough and len(var_sales_history) >= 20:\n",
    "        try:\n",
    "            m = Prophet(daily_seasonality=True)\n",
    "            m.fit(var_sales_history)\n",
    "            future = m.make_future_dataframe(periods=lead_time_days)\n",
    "            forecast = m.predict(future)\n",
    "            lead_forecast = forecast.tail(lead_time_days)\n",
    "            demand_lt = lead_forecast['yhat'].sum()\n",
    "            sigma_lt = (lead_forecast['yhat_upper'].sum() - lead_forecast['yhat_lower'].sum()) / 3.29\n",
    "            safety_stock = z * sigma_lt\n",
    "            reorder_level = int(np.round(demand_lt + safety_stock))\n",
    "            replenish_level = int(np.round(reorder_level + demand_lt))\n",
    "        except Exception as e:\n",
    "            last_week = var_sales_history.sort_values('ds').tail(7)\n",
    "            avg_daily = last_week['y'].mean() if len(last_week) else 1\n",
    "            demand_lt = avg_daily * lead_time_days\n",
    "            reorder_level = int(np.round(demand_lt))\n",
    "            replenish_level = int(np.round(demand_lt * 2))\n",
    "    else:\n",
    "        last_week = var_sales_history.sort_values('ds').tail(7)\n",
    "        avg_daily = last_week['y'].mean() if len(last_week) else 1\n",
    "        demand_lt = avg_daily * lead_time_days\n",
    "        reorder_level = int(np.round(demand_lt))\n",
    "        replenish_level = int(np.round(demand_lt * 2))\n",
    "\n",
    "    results.append({\n",
    "        'location_id': loc,\n",
    "        'variation_id': var,\n",
    "        'reorder_level': reorder_level,\n",
    "        'replenish_level': replenish_level,\n",
    "        'enough_history': enough\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac4360c3-7f13-4770-810f-c1d894817a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in names from agg_df\n",
    "results_df = results_df.merge(\n",
    "    agg_df[['item_variation_id', 'variation_name', 'name']].drop_duplicates(),\n",
    "    left_on='variation_id',\n",
    "    right_on='item_variation_id',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d8bdd04-93a3-4ef1-b0a2-af7320590cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally add last sale date\n",
    "last_sale_dates = (\n",
    "    recent_daily_var_sales.groupby(['location_id', 'variation_id'])['date']\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .rename(columns={'date': 'last_sale_date'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "740286b6-1abf-4471-9204-4992d86e9561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>variation_id</th>\n",
       "      <th>reorder_level</th>\n",
       "      <th>replenish_level</th>\n",
       "      <th>enough_history</th>\n",
       "      <th>variation_name</th>\n",
       "      <th>item_name</th>\n",
       "      <th>last_sale_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>Prices: .99</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>2025-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>Prices: 1.99</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>2025-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "      <td>Prices: 2.99</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>2025-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>49</td>\n",
       "      <td>True</td>\n",
       "      <td>Prices: 3.99</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>2025-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>Prices: 4.99</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>2025-05-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location_id  variation_id  reorder_level  replenish_level  enough_history  \\\n",
       "0          1.0           1.0             26               52           False   \n",
       "1          1.0           2.0             61               90            True   \n",
       "2          1.0           3.0             43               63            True   \n",
       "3          1.0           4.0             32               49            True   \n",
       "4          1.0           5.0             38               57            True   \n",
       "\n",
       "  variation_name item_name last_sale_date  \n",
       "0    Prices: .99    Bakery     2025-02-09  \n",
       "1   Prices: 1.99    Bakery     2025-05-23  \n",
       "2   Prices: 2.99    Bakery     2025-05-23  \n",
       "3   Prices: 3.99    Bakery     2025-05-20  \n",
       "4   Prices: 4.99    Bakery     2025-05-23  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = results_df.merge(last_sale_dates, on=['location_id', 'variation_id'], how='left')\n",
    "\n",
    "# Clean up column names for final output\n",
    "clean_df = results_df[[\n",
    "    'location_id', 'variation_id', 'reorder_level', 'replenish_level', 'enough_history',\n",
    "    'variation_name', 'name', 'last_sale_date'\n",
    "]].rename(columns={'name': 'item_name'})\n",
    "\n",
    "display(clean_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4e5c850-24cf-4b11-843d-59411fdac9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('/tmp/variation_reorder_report.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04966640-5a40-48d3-b253-69b0474ff650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File uploaded to s3://thedogspaw-small-forecast-data/results/variation_reorder_report.csv\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket = 'thedogspaw-small-forecast-data'\n",
    "s3_key = 'results/variation_reorder_report.csv'  # S3 \"folder\" + file name\n",
    "\n",
    "s3.upload_file('/tmp/variation_reorder_report.csv', bucket, s3_key)\n",
    "\n",
    "print(f\"✅ File uploaded to s3://{bucket}/{s3_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b1620-5cf2-4196-b3b3-fb8ae9f7c587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
